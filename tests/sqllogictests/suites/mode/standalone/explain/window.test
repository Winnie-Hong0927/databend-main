statement ok
CREATE DATABASE IF NOT EXISTS test_explain_window

statement ok
USE test_explain_window

statement ok
DROP TABLE IF EXISTS empsalary

statement ok
CREATE TABLE empsalary (depname string, empno bigint, salary int, enroll_date date)

query T
explain SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname ORDER BY empno) FROM empsalary ORDER BY depname, empno
----
Sort
├── output columns: [empsalary.depname (#0), empsalary.empno (#1), empsalary.salary (#2), sum(salary) OVER ( PARTITION BY depname ORDER BY empno ) (#4)]
├── sort keys: [depname ASC NULLS LAST, empno ASC NULLS LAST]
├── estimated rows: 0.00
└── Window
    ├── output columns: [empsalary.depname (#0), empsalary.empno (#1), empsalary.salary (#2), sum(salary) OVER ( PARTITION BY depname ORDER BY empno ) (#4)]
    ├── aggregate function: [sum(salary)]
    ├── partition by: [depname]
    ├── order by: [empno]
    ├── frame: [Range: Preceding(None) ~ CurrentRow]
    └── Sort
        ├── output columns: [empsalary.depname (#0), empsalary.empno (#1), empsalary.salary (#2)]
        ├── sort keys: [depname ASC NULLS LAST, empno ASC NULLS LAST]
        ├── estimated rows: 0.00
        └── LocalShuffle
            ├── output columns: [empsalary.depname (#0), empsalary.empno (#1), empsalary.salary (#2)]
            ├── shuffle by: [depname]
            └── TableScan
                ├── table: default.test_explain_window.empsalary
                ├── output columns: [depname (#0), empno (#1), salary (#2)]
                ├── read rows: 0
                ├── read size: 0
                ├── partitions total: 0
                ├── partitions scanned: 0
                ├── push downs: [filters: [], limit: NONE]
                └── estimated rows: 0.00

statement ok
set max_threads=4;

# Disable sort spilling
statement ok
set sort_spilling_memory_ratio = 0;

query T
explain pipeline SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname ORDER BY empno) FROM empsalary ORDER BY depname, empno;
----
CompoundBlockOperator(Project) × 1
  Merge to MultiSortMerge × 1
    TransformSortMerge × 4
      SortPartialTransform × 4
        Merge to Resize × 4
          Transform Window × 1
            Merge to MultiSortMerge × 1
              TransformSortMerge × 4
                SortPartialTransform × 4
                  Merge to Resize × 4
                    DeserializeDataTransform × 1
                      SyncReadParquetDataSource × 1


# Enable sort spilling
statement ok
set sort_spilling_memory_ratio = 60;

query T
explain pipeline SELECT depname, empno, salary, sum(salary) OVER (PARTITION BY depname ORDER BY empno) FROM empsalary ORDER BY depname, empno;
----
CompoundBlockOperator(Project) × 1
  Merge to MultiSortMerge × 1
    TransformSortSpill × 4
      TransformSortMerge × 4
        SortPartialTransform × 4
          Merge to Resize × 4
            Transform Window × 1
              Merge to MultiSortMerge × 1
                TransformSortSpill × 4
                  TransformSortMerge × 4
                    SortPartialTransform × 4
                      Merge to Resize × 4
                        DeserializeDataTransform × 1
                          SyncReadParquetDataSource × 1


statement ok
DROP TABLE IF EXISTS Test

statement ok
CREATE TABLE Test (k int, v int);

# push down filter in window function
query T
explain SELECT k, v FROM (SELECT *, rank() OVER (PARTITION BY k ORDER BY v DESC) AS rank FROM ((SELECT k, v FROM Test) UNION ALL (SELECT k, v FROM Test) ) t1 ) t2 WHERE rank = 1 AND k = 12;
----
Filter
├── output columns: [test.k (#0), test.v (#1)]
├── filters: [t2.rank (#4) = 1]
├── estimated rows: 0.00
└── Window
    ├── output columns: [test.k (#0), test.v (#1), rank() OVER ( PARTITION BY k ORDER BY v DESC ) (#4)]
    ├── aggregate function: [rank]
    ├── partition by: [k]
    ├── order by: [v]
    ├── frame: [Range: Preceding(None) ~ CurrentRow]
    └── Sort
        ├── output columns: [test.k (#0), test.v (#1)]
        ├── sort keys: [k ASC NULLS LAST, v DESC NULLS LAST]
        ├── estimated rows: 0.00
        └── LocalShuffle
            ├── output columns: [test.k (#0), test.v (#1)]
            ├── shuffle by: [k]
            └── UnionAll
                ├── output columns: [test.k (#0), test.v (#1)]
                ├── estimated rows: 0.00
                ├── Filter
                │   ├── output columns: [test.k (#0), test.v (#1)]
                │   ├── filters: [is_true(test.k (#0) = 12)]
                │   ├── estimated rows: 0.00
                │   └── TableScan
                │       ├── table: default.test_explain_window.test
                │       ├── output columns: [k (#0), v (#1)]
                │       ├── read rows: 0
                │       ├── read size: 0
                │       ├── partitions total: 0
                │       ├── partitions scanned: 0
                │       ├── push downs: [filters: [is_true(test.k (#0) = 12)], limit: NONE]
                │       └── estimated rows: 0.00
                └── Filter
                    ├── output columns: [test.k (#2), test.v (#3)]
                    ├── filters: [is_true(test.k (#2) = 12)]
                    ├── estimated rows: 0.00
                    └── TableScan
                        ├── table: default.test_explain_window.test
                        ├── output columns: [k (#2), v (#3)]
                        ├── read rows: 0
                        ├── read size: 0
                        ├── partitions total: 0
                        ├── partitions scanned: 0
                        ├── push downs: [filters: [is_true(test.k (#2) = 12)], limit: NONE]
                        └── estimated rows: 0.00

# cannot push down filter in window function
query T
explain SELECT k, v FROM (SELECT *, rank() OVER (PARTITION BY v ORDER BY v DESC) AS rank FROM ((SELECT k, v FROM Test) UNION ALL (SELECT k, v FROM Test) ) t1 ) t2 WHERE rank = 1 AND k = 12;
----
Filter
├── output columns: [test.k (#0), test.v (#1)]
├── filters: [t2.rank (#4) = 1, is_true(t2.k (#0) = 12)]
├── estimated rows: 0.00
└── Window
    ├── output columns: [test.k (#0), test.v (#1), rank() OVER ( PARTITION BY v ORDER BY v DESC ) (#4)]
    ├── aggregate function: [rank]
    ├── partition by: [v]
    ├── order by: [v]
    ├── frame: [Range: Preceding(None) ~ CurrentRow]
    └── Sort
        ├── output columns: [test.k (#0), test.v (#1)]
        ├── sort keys: [v ASC NULLS LAST, v DESC NULLS LAST]
        ├── estimated rows: 0.00
        └── LocalShuffle
            ├── output columns: [test.k (#0), test.v (#1)]
            ├── shuffle by: [v]
            └── UnionAll
                ├── output columns: [test.k (#0), test.v (#1)]
                ├── estimated rows: 0.00
                ├── TableScan
                │   ├── table: default.test_explain_window.test
                │   ├── output columns: [k (#0), v (#1)]
                │   ├── read rows: 0
                │   ├── read size: 0
                │   ├── partitions total: 0
                │   ├── partitions scanned: 0
                │   ├── push downs: [filters: [], limit: NONE]
                │   └── estimated rows: 0.00
                └── TableScan
                    ├── table: default.test_explain_window.test
                    ├── output columns: [k (#2), v (#3)]
                    ├── read rows: 0
                    ├── read size: 0
                    ├── partitions total: 0
                    ├── partitions scanned: 0
                    ├── push downs: [filters: [], limit: NONE]
                    └── estimated rows: 0.00

# cannot push down filter in window function
query T
explain SELECT k, v FROM (SELECT *, rank() OVER (ORDER BY v DESC) AS rank FROM ((SELECT k, v FROM Test) UNION ALL (SELECT k, v FROM Test) ) t1 ) t2 WHERE rank = 1 AND k = 12;
----
Filter
├── output columns: [test.k (#0), test.v (#1)]
├── filters: [t2.rank (#4) = 1, is_true(t2.k (#0) = 12)]
├── estimated rows: 0.00
└── Window
    ├── output columns: [test.k (#0), test.v (#1), rank() OVER ( ORDER BY v DESC ) (#4)]
    ├── aggregate function: [rank]
    ├── partition by: []
    ├── order by: [v]
    ├── frame: [Range: Preceding(None) ~ CurrentRow]
    └── Sort
        ├── output columns: [test.k (#0), test.v (#1)]
        ├── sort keys: [v DESC NULLS LAST]
        ├── estimated rows: 0.00
        └── UnionAll
            ├── output columns: [test.k (#0), test.v (#1)]
            ├── estimated rows: 0.00
            ├── TableScan
            │   ├── table: default.test_explain_window.test
            │   ├── output columns: [k (#0), v (#1)]
            │   ├── read rows: 0
            │   ├── read size: 0
            │   ├── partitions total: 0
            │   ├── partitions scanned: 0
            │   ├── push downs: [filters: [], limit: NONE]
            │   └── estimated rows: 0.00
            └── TableScan
                ├── table: default.test_explain_window.test
                ├── output columns: [k (#2), v (#3)]
                ├── read rows: 0
                ├── read size: 0
                ├── partitions total: 0
                ├── partitions scanned: 0
                ├── push downs: [filters: [], limit: NONE]
                └── estimated rows: 0.00

statement ok
drop table if exists t

statement ok
create table t(a int)

query T
explain select max(a) OVER (partition by a) FROM t qualify max(a) OVER (partition by a) > 3;
----
Filter
├── output columns: [max(a) OVER ( PARTITION BY a ) (#1)]
├── filters: [is_true(max(a) OVER ( PARTITION BY a ) (#1) > 3)]
├── estimated rows: 0.00
└── Window
    ├── output columns: [t.a (#0), max(a) OVER ( PARTITION BY a ) (#1)]
    ├── aggregate function: [max(a)]
    ├── partition by: [a]
    ├── order by: []
    ├── frame: [Range: Preceding(None) ~ Following(None)]
    └── Sort
        ├── output columns: [t.a (#0)]
        ├── sort keys: [a ASC NULLS LAST]
        ├── estimated rows: 0.00
        └── LocalShuffle
            ├── output columns: [t.a (#0)]
            ├── shuffle by: [a]
            └── TableScan
                ├── table: default.test_explain_window.t
                ├── output columns: [a (#0)]
                ├── read rows: 0
                ├── read size: 0
                ├── partitions total: 0
                ├── partitions scanned: 0
                ├── push downs: [filters: [], limit: NONE]
                └── estimated rows: 0.00

## example from: https://community.snowflake.com/s/article/Pushdown-or-Not-Pushdown
statement ok
DROP TABLE IF EXISTS tbpush

statement ok
create table tbpush(b int);

statement ok
DROP view IF EXISTS vwpush

statement ok
create view vwpush (b, rnum) as select b, row_number() over (order by b) from tbpush

query T
explain select b, row_number() over (order by b) from tbpush where b > 3;
----
Window
├── output columns: [tbpush.b (#0), row_number() OVER ( ORDER BY b ) (#1)]
├── aggregate function: [row_number]
├── partition by: []
├── order by: [b]
├── frame: [Range: Preceding(None) ~ CurrentRow]
└── Sort
    ├── output columns: [tbpush.b (#0)]
    ├── sort keys: [b ASC NULLS LAST]
    ├── estimated rows: 0.00
    └── Filter
        ├── output columns: [tbpush.b (#0)]
        ├── filters: [is_true(tbpush.b (#0) > 3)]
        ├── estimated rows: 0.00
        └── TableScan
            ├── table: default.test_explain_window.tbpush
            ├── output columns: [b (#0)]
            ├── read rows: 0
            ├── read size: 0
            ├── partitions total: 0
            ├── partitions scanned: 0
            ├── push downs: [filters: [is_true(tbpush.b (#0) > 3)], limit: NONE]
            └── estimated rows: 0.00

query T
explain select * from vwpush where b > 3;
----
Filter
├── output columns: [tbpush.b (#0), rnum (#1)]
├── filters: [is_true(vwpush.b (#0) > 3)]
├── estimated rows: 0.00
└── Window
    ├── output columns: [tbpush.b (#0), rnum (#1)]
    ├── aggregate function: [row_number]
    ├── partition by: []
    ├── order by: [b]
    ├── frame: [Range: Preceding(None) ~ CurrentRow]
    └── Sort
        ├── output columns: [tbpush.b (#0)]
        ├── sort keys: [b ASC NULLS LAST]
        ├── estimated rows: 0.00
        └── TableScan
            ├── table: default.test_explain_window.tbpush
            ├── output columns: [b (#0)]
            ├── read rows: 0
            ├── read size: 0
            ├── partitions total: 0
            ├── partitions scanned: 0
            ├── push downs: [filters: [], limit: NONE]
            └── estimated rows: 0.00

query T
explain select * from (select b, row_number() over (order by b) from tbpush) where b > 3;
----
Filter
├── output columns: [tbpush.b (#0), row_number() OVER ( ORDER BY b ) (#1)]
├── filters: [is_true(tbpush.b (#0) > 3)]
├── estimated rows: 0.00
└── Window
    ├── output columns: [tbpush.b (#0), row_number() OVER ( ORDER BY b ) (#1)]
    ├── aggregate function: [row_number]
    ├── partition by: []
    ├── order by: [b]
    ├── frame: [Range: Preceding(None) ~ CurrentRow]
    └── Sort
        ├── output columns: [tbpush.b (#0)]
        ├── sort keys: [b ASC NULLS LAST]
        ├── estimated rows: 0.00
        └── TableScan
            ├── table: default.test_explain_window.tbpush
            ├── output columns: [b (#0)]
            ├── read rows: 0
            ├── read size: 0
            ├── partitions total: 0
            ├── partitions scanned: 0
            ├── push downs: [filters: [], limit: NONE]
            └── estimated rows: 0.00

# test push down limit to window function
statement ok
drop table if exists t

statement ok
create table t (a int, b int, c string, d int, e int, f string)


# Disable sort spilling
statement ok
set sort_spilling_memory_ratio = 0;

# range frame (can not push down limit)
query T
explain pipeline select a, sum(a) over (partition by a order by a desc) from t limit 3
----
CompoundBlockOperator(Project) × 1
  LimitTransform × 1
    Transform Window × 1
      Merge to MultiSortMerge × 1
        TransformSortMerge × 4
          SortPartialTransform × 4
            Merge to Resize × 4
              DeserializeDataTransform × 1
                SyncReadParquetDataSource × 1

# Enable sort spilling
statement ok
set sort_spilling_memory_ratio = 60;

# range frame (can not push down limit)
query T
explain pipeline select a, sum(a) over (partition by a order by a desc) from t limit 3
----
CompoundBlockOperator(Project) × 1
  LimitTransform × 1
    Transform Window × 1
      Merge to MultiSortMerge × 1
        TransformSortSpill × 4
          TransformSortMerge × 4
            SortPartialTransform × 4
              Merge to Resize × 4
                DeserializeDataTransform × 1
                  SyncReadParquetDataSource × 1


# Disable sort spilling
statement ok
set sort_spilling_memory_ratio = 0;

# range frame with ranking function (can push down limit)
query T
explain pipeline select a, dense_rank() over (partition by a order by a desc) from t limit 3
----
CompoundBlockOperator(Project) × 1
  LimitTransform × 1
    Transform Window × 1
      Merge to MultiSortMerge × 1
        TransformSortMerge × 4
          SortPartialTransform × 4
            Merge to Resize × 4
              DeserializeDataTransform × 1
                SyncReadParquetDataSource × 1

# rows frame single window (can push down limit)
query T
explain pipeline select a, sum(a) over (partition by a order by a desc rows between unbounded preceding and current row) from t limit 3
----
CompoundBlockOperator(Project) × 1
  LimitTransform × 1
    Transform Window × 1
      Merge to MultiSortMerge × 1
        TransformSortMerge × 4
          SortPartialTransform × 4
            Merge to Resize × 4
              DeserializeDataTransform × 1
                SyncReadParquetDataSource × 1

# rows frame single window (can not push down limit)
query T
explain pipeline select a, sum(a) over (partition by a order by a desc rows between unbounded preceding and unbounded following) from t limit 3
----
CompoundBlockOperator(Project) × 1
  LimitTransform × 1
    Transform Window × 1
      Merge to MultiSortMerge × 1
        TransformSortMerge × 4
          SortPartialTransform × 4
            Merge to Resize × 4
              DeserializeDataTransform × 1
                SyncReadParquetDataSource × 1

# rows frame multi window (can not push down limit)
query T
explain pipeline select a, sum(a) over (partition by a order by a desc rows between unbounded preceding and current row),
avg(a) over (order by a rows between unbounded preceding and current row) from t limit 3
----
CompoundBlockOperator(Project) × 1
  LimitTransform × 1
    Transform Window × 1
      Merge to MultiSortMerge × 1
        TransformSortMerge × 4
          SortPartialTransform × 4
            Merge to Resize × 4
              Transform Window × 1
                Merge to MultiSortMerge × 1
                  TransformSortMerge × 4
                    SortPartialTransform × 4
                      Merge to Resize × 4
                        DeserializeDataTransform × 1
                          SyncReadParquetDataSource × 1

# row fetch with window function(pipeline explain)
query T
explain pipeline select *, sum(a) over (partition by a order by a desc rows between unbounded preceding and current row) from t where a > 1 order by b limit 3;
----
CompoundBlockOperator(Project) × 1
  TransformRowsFetcher × 1
    LimitTransform × 1
      Merge to MultiSortMerge × 1
        TransformSortMergeLimit × 4
          SortPartialTransform × 4
            Merge to Resize × 4
              Transform Window × 1
                Merge to MultiSortMerge × 1
                  TransformSortMerge × 4
                    SortPartialTransform × 4
                      Merge to Resize × 4
                        TransformFilter × 1
                          AddInternalColumnsTransform × 1
                            DeserializeDataTransform × 1
                              SyncReadParquetDataSource × 1

# row fetch with window function(plan explain)
query T
explain select *, sum(a) over (partition by a order by a desc rows between unbounded preceding and current row) from t where a > 1 order by b limit 3
----
RowFetch
├── output columns: [t.a (#0), t.b (#1), t._row_id (#7), sum(a) OVER ( PARTITION BY a ORDER BY a DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ) (#6), t.c (#2), t.d (#3), t.e (#4), t.f (#5)]
├── columns to fetch: [c, d, e, f]
├── estimated rows: 0.00
└── Limit
    ├── output columns: [t.a (#0), t.b (#1), t._row_id (#7), sum(a) OVER ( PARTITION BY a ORDER BY a DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ) (#6)]
    ├── limit: 3
    ├── offset: 0
    ├── estimated rows: 0.00
    └── Sort
        ├── output columns: [t.a (#0), t.b (#1), t._row_id (#7), sum(a) OVER ( PARTITION BY a ORDER BY a DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ) (#6)]
        ├── sort keys: [b ASC NULLS LAST]
        ├── estimated rows: 0.00
        └── Window
            ├── output columns: [t.a (#0), t.b (#1), t._row_id (#7), sum(a) OVER ( PARTITION BY a ORDER BY a DESC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW ) (#6)]
            ├── aggregate function: [sum(a)]
            ├── partition by: [a]
            ├── order by: [a]
            ├── frame: [Rows: Preceding(None) ~ CurrentRow]
            └── Sort
                ├── output columns: [t.a (#0), t.b (#1), t._row_id (#7)]
                ├── sort keys: [a ASC NULLS LAST, a DESC NULLS LAST]
                ├── estimated rows: 0.00
                └── LocalShuffle
                    ├── output columns: [t.a (#0), t.b (#1), t._row_id (#7)]
                    ├── shuffle by: [a]
                    └── Filter
                        ├── output columns: [t.a (#0), t.b (#1), t._row_id (#7)]
                        ├── filters: [is_true(t.a (#0) > 1)]
                        ├── estimated rows: 0.00
                        └── TableScan
                            ├── table: default.test_explain_window.t
                            ├── output columns: [a (#0), b (#1), _row_id (#7)]
                            ├── read rows: 0
                            ├── read size: 0
                            ├── partitions total: 0
                            ├── partitions scanned: 0
                            ├── push downs: [filters: [is_true(t.a (#0) > 1)], limit: NONE]
                            └── estimated rows: 0.00

statement ok
drop table if exists table43764_orc

statement ok
CREATE TABLE table43764_orc (rowkey VARCHAR NOT NULL, time TIMESTAMP NULL, sirc_action VARCHAR NULL, sirc_operation_count DECIMAL(36, 16) NULL, akc087 VARCHAR NULL, aae035 VARCHAR)

# window in subquery
query T
explain pipeline select time, rowkey from (select *, row_number() over(partition by rowkey order by time desc) as rn from table43764_orc) a where rn = 1 limit 4
----
CompoundBlockOperator(Project) × 1
  LimitTransform × 1
    TransformFilter × 1
      Transform Window × 1
        Merge to MultiSortMerge × 1
          TransformSortMerge × 4
            SortPartialTransform × 4
              Merge to Resize × 4
                DeserializeDataTransform × 1
                  SyncReadParquetDataSource × 1

# same order multi window
query T
explain  pipeline select *,lead(number,1, 42) over (order by number), lead(number,2,44) over (order by number), lead(number,3,44) over (order by number) from numbers(5);
----
CompoundBlockOperator(Project) × 1
  Transform Window × 1
    CompoundBlockOperator(Map) × 1
      Transform Window × 1
        CompoundBlockOperator(Map) × 1
          Transform Window × 1
            Merge to MultiSortMerge × 1
              TransformSortMerge × 4
                SortPartialTransform × 4
                  Merge to Resize × 4
                    CompoundBlockOperator(Map) × 1
                      NumbersSourceTransform × 1

# same order same partiton by multi window
query T
explain pipeline select number, lead(number,1, 0) over (partition by number % 3 order by number+ 1), lead(number,2, 0) over (partition by number % 3 order by number + 1) from numbers(50);
----
CompoundBlockOperator(Project) × 1
  Transform Window × 1
    CompoundBlockOperator(Map) × 1
      Transform Window × 1
        Merge to MultiSortMerge × 1
          TransformSortMerge × 4
            SortPartialTransform × 4
              Merge to Resize × 4
                CompoundBlockOperator(Map) × 1
                  NumbersSourceTransform × 1


statement ok
DROP DATABASE test_explain_window;
